## Problem statement :

The marketing department at NewsBytes frequently uses long URLs with UTM tracking for various campaigns. However, these URLs often encounter issues when copied across different platforms, such as emails, spreadsheets, and documents, leading to formatting errors and potential loss of tracking data. To address this challenge, there is a need to design and implement a URL hashing system that can preserve the integrity of URLs while ensuring click tracking functionality and maintaining privacy.

## Key Requirements:

The system should be ready to execute out of the box.
URL length cannot be restricted, and query parameters must be preserved.
Click tracking functionality should be implemented, while ensuring privacy-aware hashed URLs.
The generated URLs may be single-use or limited use only.


## Assumption:
1) The input url must be at max 2MB in size which is highest limit on the length of the URL permitted on various browsers.If your request url is more than 2MB than we suggest you to add it in requestbody instead of url parameters
2) The shortened url will do only one task : It will redirect it to original url.(All the paramters will be preserved).We cannot add any new query paramter or any other meta data to shortened url. You should create new shortened url for new parameters.
3) The URL can be max available for 30 days.

## How it works?

1)Input url consisting of all parameter like query,utm etc.
2)Creating HASH of 64 bits using SHA256 algorithm whose collision rate is negligible.
3)Using 62bit encoder to produce 6 digit unique code which is shortened urlid.

If newsbytes is generating 1000 news everyday and if there are atleast 30 query and utm parameters combination and we store it for 30 days than 
    reuqirement 1000*30*30 = 9lac shortened url per month
    base 62 generates 62^6 unique entries which is far greater than our requirements.
    

We will do generated 64 character hash mapping to url code which is 6 character.
This will save our time complexity. Let's see

No two url will produce same hash value. Also A single url will never produce two different hash value and 62 bit encode.
We will be using monogdb as database due to it's horizontal scaling property. Also it is faster for searching operation.
We will create index on url-id [urlid is 6 digit code generated by slicing 62bit encoder] . This will help us reduce our time complexity for searching to O(logn) as for every query we will use urlid as key.

## How to use it?
1)You need to install all the dependencies in your system as mentioned in requirements.txt file
2)The code is easily customisable according to your system requirement. Also you can change api names and can even use your own domain name.
